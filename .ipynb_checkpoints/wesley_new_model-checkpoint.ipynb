{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import  Input,  Dense, LSTM, Concatenate, Dropout, Bidirectional\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_columns = [ 'guitrancourt_Speed(m/s)', 'guitrancourt_Direction (deg N)',\n",
    "       'lieusaint_Speed(m/s)', 'lieusaint_Direction (deg N)',\n",
    "       'lvs-pussay_Speed(m/s)', 'lvs-pussay_Direction (deg N)',\n",
    "       'parc-du-gatinais_Speed(m/s)', 'parc-du-gatinais_Direction (deg N)',\n",
    "       'arville_Speed(m/s)', 'arville_Direction (deg N)',\n",
    "       'boissy-la-riviere_Speed(m/s)', 'boissy-la-riviere_Direction (deg N)',\n",
    "       'angerville-1_Speed(m/s)', 'angerville-1_Direction (deg N)',\n",
    "       'angerville-2_Speed(m/s)', 'angerville-2_Direction (deg N)',\n",
    "       'guitrancourt-b_Speed(m/s)', 'guitrancourt-b_Direction (deg N)',\n",
    "       'lieusaint-b_Speed(m/s)', 'lieusaint-b_Direction (deg N)',\n",
    "       'lvs-pussay-b_Speed(m/s)', 'lvs-pussay-b_Direction (deg N)',\n",
    "       'parc-du-gatinais-b_Speed(m/s)', 'parc-du-gatinais-b_Direction (deg N)',\n",
    "       'arville-b_Speed(m/s)', 'arville-b_Direction (deg N)',\n",
    "       'boissy-la-riviere-b_Speed(m/s)',\n",
    "       'boissy-la-riviere-b_Direction (deg N)', 'angerville-1-b_Speed(m/s)',\n",
    "       'angerville-1-b_Direction (deg N)', 'angerville-2-b_Speed(m/s)',\n",
    "       'angerville-2-b_Direction (deg N)']\n",
    "wind_angle_columns = ['guitrancourt_Direction (deg N)','lieusaint_Direction (deg N)','lvs-pussay_Direction (deg N)',\n",
    " 'parc-du-gatinais_Direction (deg N)','arville_Direction (deg N)','boissy-la-riviere_Direction (deg N)','angerville-1_Direction (deg N)', \n",
    " 'angerville-2_Direction (deg N)','guitrancourt-b_Direction (deg N)','lieusaint-b_Direction (deg N)','lvs-pussay-b_Direction (deg N)',\n",
    " 'parc-du-gatinais-b_Direction (deg N)','arville-b_Direction (deg N)','boissy-la-riviere-b_Direction (deg N)','angerville-1-b_Direction (deg N)','angerville-2-b_Direction (deg N)'\n",
    "\n",
    "]\n",
    "wind_speed_columns = set(wind_columns) - set(wind_angle_columns)\n",
    "wind_speed_columns = list(wind_speed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_energy_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert it to datetime\n",
    "df['datetime'] = pd.to_datetime(df.datetime)\n",
    "agg_columns =  [\"datetime\",\"Wind\"]\n",
    "required_columns = [\"Hours\"] + agg_columns + [i for i in df.columns[12:]]\n",
    "df_agg = df[agg_columns].groupby([df.datetime.dt.floor(\"H\")]).agg([\"mean\",\"median\",\"max\",\"min\",\"std\",\"sum\"])\n",
    "df_agg.columns = df_agg.columns.map('_'.join)\n",
    "df_agg = df_agg.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_agg.merge(df[required_columns], how=\"left\", on=\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = 8758\n",
    "test_index = 17517\n",
    "holdout_index = 26276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Wind_mean</th>\n",
       "      <th>Wind_median</th>\n",
       "      <th>Wind_max</th>\n",
       "      <th>Wind_min</th>\n",
       "      <th>Wind_std</th>\n",
       "      <th>Wind_sum</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Wind</th>\n",
       "      <th>guitrancourt_Speed(m/s)</th>\n",
       "      <th>...</th>\n",
       "      <th>parc-du-gatinais-b_Speed(m/s)</th>\n",
       "      <th>parc-du-gatinais-b_Direction (deg N)</th>\n",
       "      <th>arville-b_Speed(m/s)</th>\n",
       "      <th>arville-b_Direction (deg N)</th>\n",
       "      <th>boissy-la-riviere-b_Speed(m/s)</th>\n",
       "      <th>boissy-la-riviere-b_Direction (deg N)</th>\n",
       "      <th>angerville-1-b_Speed(m/s)</th>\n",
       "      <th>angerville-1-b_Direction (deg N)</th>\n",
       "      <th>angerville-2-b_Speed(m/s)</th>\n",
       "      <th>angerville-2-b_Direction (deg N)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>02:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.961667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.505</td>\n",
       "      <td>221.333333</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>221.333333</td>\n",
       "      <td>2.723333</td>\n",
       "      <td>221.833333</td>\n",
       "      <td>2.72</td>\n",
       "      <td>223.5</td>\n",
       "      <td>2.72</td>\n",
       "      <td>223.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>03:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.063333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>217.666667</td>\n",
       "      <td>2.513333</td>\n",
       "      <td>217.666667</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>217.666667</td>\n",
       "      <td>2.70</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.165000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.495</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>213.500000</td>\n",
       "      <td>2.68</td>\n",
       "      <td>214.5</td>\n",
       "      <td>2.68</td>\n",
       "      <td>214.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.490</td>\n",
       "      <td>210.333333</td>\n",
       "      <td>2.506667</td>\n",
       "      <td>210.333333</td>\n",
       "      <td>2.703333</td>\n",
       "      <td>209.333333</td>\n",
       "      <td>2.66</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>06:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.368333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.485</td>\n",
       "      <td>206.666667</td>\n",
       "      <td>2.503333</td>\n",
       "      <td>206.666667</td>\n",
       "      <td>2.696667</td>\n",
       "      <td>205.166667</td>\n",
       "      <td>2.64</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.64</td>\n",
       "      <td>205.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  Wind_mean  Wind_median  Wind_max  Wind_min  Wind_std  \\\n",
       "0 2017-01-01 01:00:00        0.0          0.0       0.0       0.0       0.0   \n",
       "1 2017-01-01 02:00:00        0.0          0.0       0.0       0.0       0.0   \n",
       "2 2017-01-01 03:00:00        0.0          0.0       0.0       0.0       0.0   \n",
       "3 2017-01-01 04:00:00        0.0          0.0       0.0       0.0       0.0   \n",
       "4 2017-01-01 05:00:00        0.0          0.0       0.0       0.0       0.0   \n",
       "\n",
       "   Wind_sum  Hours  Wind  guitrancourt_Speed(m/s)  ...  \\\n",
       "0       0.0  02:00   0.0                 1.961667  ...   \n",
       "1       0.0  03:00   0.0                 2.063333  ...   \n",
       "2       0.0  04:00   0.0                 2.165000  ...   \n",
       "3       0.0  05:00   0.0                 2.266667  ...   \n",
       "4       0.0  06:00   0.0                 2.368333  ...   \n",
       "\n",
       "   parc-du-gatinais-b_Speed(m/s)  parc-du-gatinais-b_Direction (deg N)  \\\n",
       "0                          2.505                            221.333333   \n",
       "1                          2.500                            217.666667   \n",
       "2                          2.495                            214.000000   \n",
       "3                          2.490                            210.333333   \n",
       "4                          2.485                            206.666667   \n",
       "\n",
       "   arville-b_Speed(m/s)  arville-b_Direction (deg N)  \\\n",
       "0              2.516667                   221.333333   \n",
       "1              2.513333                   217.666667   \n",
       "2              2.510000                   214.000000   \n",
       "3              2.506667                   210.333333   \n",
       "4              2.503333                   206.666667   \n",
       "\n",
       "   boissy-la-riviere-b_Speed(m/s)  boissy-la-riviere-b_Direction (deg N)  \\\n",
       "0                        2.723333                             221.833333   \n",
       "1                        2.716667                             217.666667   \n",
       "2                        2.710000                             213.500000   \n",
       "3                        2.703333                             209.333333   \n",
       "4                        2.696667                             205.166667   \n",
       "\n",
       "   angerville-1-b_Speed(m/s)  angerville-1-b_Direction (deg N)  \\\n",
       "0                       2.72                             223.5   \n",
       "1                       2.70                             219.0   \n",
       "2                       2.68                             214.5   \n",
       "3                       2.66                             210.0   \n",
       "4                       2.64                             205.5   \n",
       "\n",
       "   angerville-2-b_Speed(m/s)  angerville-2-b_Direction (deg N)  \n",
       "0                       2.72                             223.5  \n",
       "1                       2.70                             219.0  \n",
       "2                       2.68                             214.5  \n",
       "3                       2.66                             210.0  \n",
       "4                       2.64                             205.5  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interpolated = df_merged.interpolate(method=\"linear\")\n",
    "df_interpolated = df_interpolated[2:]\n",
    "df_interpolated = df_interpolated.reset_index(drop=True)\n",
    "df_interpolated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_sum_T_plus_18 = df_interpolated.Wind_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_len(df):\n",
    "    return df.shape[0] - df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lag(series,number_of_frame,lead_time=18,title_name=\"Wind_mean_T_plus_\"):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(lead_time,number_of_frame+lead_time):\n",
    "        df[title_name+ str(-i)] = series.shift(-i-lead_time)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wind sum frame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_sum_from_0_frame_5 = get_lag(wind_sum_T_plus_18,5) # T0\n",
    "wind_sum_lag_29_frame_3 = get_lag(wind_sum_T_plus_18,3,29) #T-29 lag_month\n",
    "wind_sum_lag_379_frame_3 = get_lag(wind_sum_T_plus_18,3,379) #T-379 lag month\n",
    "wind_sum_target = get_lag(wind_sum_T_plus_18,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guitrancourt_Speed(m/s)',\n",
       " 'lvs-pussay_Speed(m/s)',\n",
       " 'parc-du-gatinais_Speed(m/s)',\n",
       " 'guitrancourt-b_Speed(m/s)',\n",
       " 'lieusaint-b_Speed(m/s)',\n",
       " 'lvs-pussay-b_Speed(m/s)',\n",
       " 'arville_Speed(m/s)',\n",
       " 'boissy-la-riviere_Speed(m/s)',\n",
       " 'angerville-1-b_Speed(m/s)',\n",
       " 'angerville-2_Speed(m/s)',\n",
       " 'angerville-1_Speed(m/s)',\n",
       " 'boissy-la-riviere-b_Speed(m/s)',\n",
       " 'lieusaint_Speed(m/s)',\n",
       " 'angerville-2-b_Speed(m/s)',\n",
       " 'parc-du-gatinais-b_Speed(m/s)',\n",
       " 'arville-b_Speed(m/s)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get wind speed frame data\n",
    "wind_speed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind_speed = df_interpolated[wind_speed_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_group_1 = [\"guitrancourt_Speed(m/s)\",\"guitrancourt-b_Speed(m/s)\",\"lvs-pussay-b_Speed(m/s)\"]#0,1,2\n",
    "wind_speed_group_2 = list(set(wind_speed_columns) - set(wind_speed_group_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind_speed_group_1 = []\n",
    "for i in wind_speed_group_1:\n",
    "    df_wind_speed_group_1.append(get_lag(df_wind_speed[i],3,0,i+\"_T_plus_\"))\n",
    "    \n",
    "df_wind_speed_group_1 = pd.concat(df_wind_speed_group_1,axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind_speed_group_2 = []\n",
    "for i in wind_speed_group_2:\n",
    "    df_wind_speed_group_2.append(get_lag(df_wind_speed[i],3,-1,i+\"_T_plus_\"))\n",
    "df_wind_speed_group_2 = pd.concat(df_wind_speed_group_2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistance = np.array(get_lag(wind_sum_T_plus_18,1,18))+np.array(get_lag(wind_sum_T_plus_18,1,19))+np.array(get_lag(wind_sum_T_plus_18,1,30))\n",
    "persistance /= 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost = get_loss_len(wind_sum_lag_379_frame_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lvs-pussay_Speed(m/s)_T_plus_1</th>\n",
       "      <th>lvs-pussay_Speed(m/s)_T_plus_0</th>\n",
       "      <th>lvs-pussay_Speed(m/s)_T_plus_-1</th>\n",
       "      <th>lieusaint-b_Speed(m/s)_T_plus_1</th>\n",
       "      <th>lieusaint-b_Speed(m/s)_T_plus_0</th>\n",
       "      <th>lieusaint-b_Speed(m/s)_T_plus_-1</th>\n",
       "      <th>boissy-la-riviere_Speed(m/s)_T_plus_1</th>\n",
       "      <th>boissy-la-riviere_Speed(m/s)_T_plus_0</th>\n",
       "      <th>boissy-la-riviere_Speed(m/s)_T_plus_-1</th>\n",
       "      <th>angerville-1-b_Speed(m/s)_T_plus_1</th>\n",
       "      <th>...</th>\n",
       "      <th>arville_Speed(m/s)_T_plus_-1</th>\n",
       "      <th>angerville-2_Speed(m/s)_T_plus_1</th>\n",
       "      <th>angerville-2_Speed(m/s)_T_plus_0</th>\n",
       "      <th>angerville-2_Speed(m/s)_T_plus_-1</th>\n",
       "      <th>boissy-la-riviere-b_Speed(m/s)_T_plus_1</th>\n",
       "      <th>boissy-la-riviere-b_Speed(m/s)_T_plus_0</th>\n",
       "      <th>boissy-la-riviere-b_Speed(m/s)_T_plus_-1</th>\n",
       "      <th>arville-b_Speed(m/s)_T_plus_1</th>\n",
       "      <th>arville-b_Speed(m/s)_T_plus_0</th>\n",
       "      <th>arville-b_Speed(m/s)_T_plus_-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.773333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.558333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.723333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>2.773333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.773333</td>\n",
       "      <td>1.886667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.723333</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>2.513333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.82</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>2.773333</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.773333</td>\n",
       "      <td>1.886667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.72</td>\n",
       "      <td>...</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.723333</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>2.513333</td>\n",
       "      <td>2.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.93</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.773333</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>2.786667</td>\n",
       "      <td>1.886667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.113333</td>\n",
       "      <td>2.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>2.703333</td>\n",
       "      <td>2.513333</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>2.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.04</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>2.786667</td>\n",
       "      <td>2.793333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.113333</td>\n",
       "      <td>2.226667</td>\n",
       "      <td>2.68</td>\n",
       "      <td>...</td>\n",
       "      <td>1.991667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>2.703333</td>\n",
       "      <td>2.696667</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>2.506667</td>\n",
       "      <td>2.503333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lvs-pussay_Speed(m/s)_T_plus_1  lvs-pussay_Speed(m/s)_T_plus_0  \\\n",
       "0                             NaN                             NaN   \n",
       "1                             NaN                            1.82   \n",
       "2                            1.82                            1.93   \n",
       "3                            1.93                            2.04   \n",
       "4                            2.04                            2.15   \n",
       "\n",
       "   lvs-pussay_Speed(m/s)_T_plus_-1  lieusaint-b_Speed(m/s)_T_plus_1  \\\n",
       "0                             1.82                              NaN   \n",
       "1                             1.93                              NaN   \n",
       "2                             2.04                         2.766667   \n",
       "3                             2.15                         2.773333   \n",
       "4                             2.26                         2.780000   \n",
       "\n",
       "   lieusaint-b_Speed(m/s)_T_plus_0  lieusaint-b_Speed(m/s)_T_plus_-1  \\\n",
       "0                              NaN                          2.766667   \n",
       "1                         2.766667                          2.773333   \n",
       "2                         2.773333                          2.780000   \n",
       "3                         2.780000                          2.786667   \n",
       "4                         2.786667                          2.793333   \n",
       "\n",
       "   boissy-la-riviere_Speed(m/s)_T_plus_1  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                               1.773333   \n",
       "3                               1.886667   \n",
       "4                               2.000000   \n",
       "\n",
       "   boissy-la-riviere_Speed(m/s)_T_plus_0  \\\n",
       "0                                    NaN   \n",
       "1                               1.773333   \n",
       "2                               1.886667   \n",
       "3                               2.000000   \n",
       "4                               2.113333   \n",
       "\n",
       "   boissy-la-riviere_Speed(m/s)_T_plus_-1  angerville-1-b_Speed(m/s)_T_plus_1  \\\n",
       "0                                1.773333                                 NaN   \n",
       "1                                1.886667                                 NaN   \n",
       "2                                2.000000                                2.72   \n",
       "3                                2.113333                                2.70   \n",
       "4                                2.226667                                2.68   \n",
       "\n",
       "   ...  arville_Speed(m/s)_T_plus_-1  angerville-2_Speed(m/s)_T_plus_1  \\\n",
       "0  ...                      1.558333                               NaN   \n",
       "1  ...                      1.666667                               NaN   \n",
       "2  ...                      1.775000                              1.78   \n",
       "3  ...                      1.883333                              1.89   \n",
       "4  ...                      1.991667                              2.00   \n",
       "\n",
       "   angerville-2_Speed(m/s)_T_plus_0  angerville-2_Speed(m/s)_T_plus_-1  \\\n",
       "0                               NaN                               1.78   \n",
       "1                              1.78                               1.89   \n",
       "2                              1.89                               2.00   \n",
       "3                              2.00                               2.11   \n",
       "4                              2.11                               2.22   \n",
       "\n",
       "   boissy-la-riviere-b_Speed(m/s)_T_plus_1  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                 2.723333   \n",
       "3                                 2.716667   \n",
       "4                                 2.710000   \n",
       "\n",
       "   boissy-la-riviere-b_Speed(m/s)_T_plus_0  \\\n",
       "0                                      NaN   \n",
       "1                                 2.723333   \n",
       "2                                 2.716667   \n",
       "3                                 2.710000   \n",
       "4                                 2.703333   \n",
       "\n",
       "   boissy-la-riviere-b_Speed(m/s)_T_plus_-1  arville-b_Speed(m/s)_T_plus_1  \\\n",
       "0                                  2.723333                            NaN   \n",
       "1                                  2.716667                            NaN   \n",
       "2                                  2.710000                       2.516667   \n",
       "3                                  2.703333                       2.513333   \n",
       "4                                  2.696667                       2.510000   \n",
       "\n",
       "   arville-b_Speed(m/s)_T_plus_0  arville-b_Speed(m/s)_T_plus_-1  \n",
       "0                            NaN                        2.516667  \n",
       "1                       2.516667                        2.513333  \n",
       "2                       2.513333                        2.510000  \n",
       "3                       2.510000                        2.506667  \n",
       "4                       2.506667                        2.503333  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wind_speed_group_2.head() # 2na as i shifted 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_sum_from_0_frame_5_dropna = wind_sum_from_0_frame_5[2:-lost].reset_index(drop=True)\n",
    "wind_sum_lag_29_frame_3_dropna  = wind_sum_lag_29_frame_3[2:-lost].reset_index(drop=True)\n",
    "wind_sum_lag_379_frame_3_dropna  = wind_sum_lag_379_frame_3[2:-lost].reset_index(drop=True)\n",
    "wind_speed_group_1_dropna  = df_wind_speed_group_1[2:-lost].reset_index(drop=True)\n",
    "wind_speed_group_2_dropna  = df_wind_speed_group_2[2:-lost].reset_index(drop=True)\n",
    "wind_sum_target_dropna = wind_sum_target[2:-lost]\n",
    "persistance_dropna = persistance[2:-lost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lvs-pussay_Speed(m/s)',\n",
       " 'lieusaint-b_Speed(m/s)',\n",
       " 'boissy-la-riviere_Speed(m/s)',\n",
       " 'angerville-1-b_Speed(m/s)',\n",
       " 'angerville-1_Speed(m/s)',\n",
       " 'lieusaint_Speed(m/s)',\n",
       " 'angerville-2-b_Speed(m/s)',\n",
       " 'parc-du-gatinais-b_Speed(m/s)',\n",
       " 'parc-du-gatinais_Speed(m/s)',\n",
       " 'arville_Speed(m/s)',\n",
       " 'angerville-2_Speed(m/s)',\n",
       " 'boissy-la-riviere-b_Speed(m/s)',\n",
       " 'arville-b_Speed(m/s)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_speed_group_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wind_sum_from_0_frame_5 = wind_sum_from_0_frame_5_dropna[:train_index]\n",
    "test_wind_sum_from_0_frame_5 = wind_sum_from_0_frame_5_dropna[train_index:test_index]\n",
    "holdout_wind_sum_from_0_frame_5 = wind_sum_from_0_frame_5_dropna[test_index:holdout_index]\n",
    "\n",
    "train_wind_sum_lag_29_frame_3 = wind_sum_lag_29_frame_3_dropna[:train_index]\n",
    "test_wind_sum_lag_29_frame_3 = wind_sum_lag_29_frame_3_dropna[train_index:test_index]\n",
    "holdout_wind_sum_lag_29_frame_3 = wind_sum_lag_29_frame_3_dropna[test_index:holdout_index]\n",
    "\n",
    "train_wind_sum_lag_379_frame_3 = wind_sum_lag_379_frame_3_dropna[:train_index]\n",
    "test_wind_sum_lag_379_frame_3 = wind_sum_lag_379_frame_3_dropna[train_index:test_index]\n",
    "holdout_wind_sum_lag_379_frame_3 = wind_sum_lag_379_frame_3_dropna[test_index:holdout_index]\n",
    "\n",
    "train_wind_speed_group_1 = wind_speed_group_1_dropna[:train_index]\n",
    "test_wind_speed_group_1  = wind_speed_group_1_dropna[train_index:test_index]\n",
    "holdout_wind_speed_group_1  = wind_speed_group_1_dropna[test_index:holdout_index]\n",
    "\n",
    "train_wind_speed_group_2 = wind_speed_group_2_dropna[:train_index]\n",
    "test_wind_speed_group_2  = wind_speed_group_2_dropna[train_index:test_index]\n",
    "holdout_wind_speed_group_2  = wind_speed_group_2_dropna[test_index:holdout_index]\n",
    "\n",
    "y = wind_sum_target\n",
    "train_y = y[:train_index]\n",
    "test_y = y[train_index:test_index]\n",
    "holdout_y = y[train_index:test_index]\n",
    "\n",
    "train_persistance = persistance[:train_index]\n",
    "test_persistance = persistance[train_index:test_index]\n",
    "holdout_persistance = persistance[test_index:holdout_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_sum_from_0_frame_5_sc = MinMaxScaler()\n",
    "wind_sum_lag_29_frame_3_sc  = MinMaxScaler()\n",
    "wind_sum_lag_379_frame_3_sc  = MinMaxScaler()\n",
    "wind_speed_group_1_sc       = MinMaxScaler()\n",
    "wind_speed_group_2_sc        = MinMaxScaler()\n",
    "y_scaler_sc                = MinMaxScaler()\n",
    "p_scaler_sc                = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wind_sum_from_0_frame_5_norm = wind_sum_from_0_frame_5_sc.fit_transform(train_wind_sum_from_0_frame_5)\n",
    "train_wind_sum_lag_29_frame_3_norm = wind_sum_lag_29_frame_3_sc.fit_transform(train_wind_sum_lag_29_frame_3)\n",
    "train_wind_sum_lag_379_frame_3_norm = wind_sum_lag_379_frame_3_sc.fit_transform(train_wind_sum_lag_379_frame_3)\n",
    "train_wind_speed_group_1_norm = wind_speed_group_1_sc.fit_transform(train_wind_speed_group_1)       \n",
    "train_wind_speed_group_2_norm = wind_speed_group_2_sc.fit_transform(train_wind_speed_group_2)      \n",
    "train_y_norm  = y_scaler_sc.fit_transform(train_y)                \n",
    "train_persistance_norm  = p_scaler_sc.fit_transform(train_persistance)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wind_sum_from_0_frame_5_norm = wind_sum_from_0_frame_5_sc.transform(test_wind_sum_from_0_frame_5)\n",
    "test_wind_sum_lag_29_frame_3_norm = wind_sum_lag_29_frame_3_sc.transform(test_wind_sum_lag_29_frame_3)\n",
    "test_wind_sum_lag_379_frame_3_norm = wind_sum_lag_379_frame_3_sc.transform(test_wind_sum_lag_379_frame_3)\n",
    "test_wind_speed_group_1_norm = wind_speed_group_1_sc.transform(test_wind_speed_group_1)       \n",
    "test_wind_speed_group_2_norm = wind_speed_group_2_sc.transform(test_wind_speed_group_2)      \n",
    "test_y_norm = y_scaler_sc.transform(test_y)                \n",
    "test_persistance_norm = p_scaler_sc.transform(test_persistance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_wind_sum_from_0_frame_5_norm = wind_sum_from_0_frame_5_sc.transform(holdout_wind_sum_from_0_frame_5)\n",
    "holdout_wind_sum_lag_29_frame_3_norm = wind_sum_lag_29_frame_3_sc.transform(holdout_wind_sum_lag_29_frame_3)\n",
    "holdout_wind_sum_lag_379_frame_3_norm = wind_sum_lag_379_frame_3_sc.transform(holdout_wind_sum_lag_379_frame_3)\n",
    "holdout_wind_speed_group_1_norm = wind_speed_group_1_sc.transform(holdout_wind_speed_group_1)       \n",
    "holdout_wind_speed_group_2_norm = wind_speed_group_2_sc.transform(holdout_wind_speed_group_2)      \n",
    "holdout_y_norm = y_scaler_sc.transform(holdout_y)                \n",
    "holdout_persistance_norm = p_scaler_sc.transform(holdout_persistance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind_sum_5 = StandardScaler()\n",
    "# wind_sum_3 = StandardScaler()\n",
    "# wind_sum_1 = StandardScaler()\n",
    "# wind_speed_group1 = StandardScaler()\n",
    "# wind_speed_group2 = StandardScaler()\n",
    "# wind_sum__from_0_frame_5_norm = wind_sum_5.fit_transform(wind_sum__from_t_frame_5_dropna)\n",
    "\n",
    "# wind_sum_lag_29_frame_3_norm = wind_sum_3.fit_transform(wind_sum_lag_29_frame_3_dropna)\n",
    "# wind_sum_lag_379_frame_3_norm = wind_sum_3.transform(wind_sum_lag_29_frame_3_dropna)\n",
    "\n",
    "# persistance_norm = wind_sum_1.fit_transform(persistance)\n",
    "\n",
    "# wind_speed_group_1_norm = wind_speed_group1.fit_transform(wind_speed_group_1_dropna)\n",
    "# wind_speed_group_2_norm = wind_speed_group2.fit_transform(wind_speed_group_2_dropna)\n",
    "\n",
    "# y = wind_sum_1.transform(wind_sum_target)[2:-lost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_things = [train_wind_sum_from_0_frame_5_norm,test_wind_sum_from_0_frame_5_norm,holdout_wind_sum_from_0_frame_5_norm,\n",
    " train_wind_sum_lag_29_frame_3_norm,test_wind_sum_lag_29_frame_3_norm,holdout_wind_sum_lag_29_frame_3_norm,\n",
    " train_wind_sum_lag_379_frame_3_norm,test_wind_sum_lag_379_frame_3_norm ,holdout_wind_sum_lag_379_frame_3_norm,\n",
    " train_wind_speed_group_1_norm,test_wind_speed_group_1_norm ,holdout_wind_speed_group_1_norm,\n",
    " train_wind_speed_group_2_norm,test_wind_speed_group_2_norm ,holdout_wind_speed_group_2_norm,\n",
    "]\n",
    "all_pad_size =[ i.reshape((*i.shape),1) for i in all_things]\n",
    "\n",
    "train_feature_input = [all_pad_size[i] for i in range(0,len(all_pad_size),3)]\n",
    "\n",
    "test_feature_input = [all_pad_size[i] for i in range(1,len(all_pad_size),3)]\n",
    "\n",
    "holdout_feature_input = [all_pad_size[i] for i in range(2,len(all_pad_size),3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8759, 5, 1)\n",
      "(8759, 3, 1)\n",
      "(8759, 3, 1)\n",
      "(8759, 9, 1)\n",
      "(8759, 39, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(holdout_feature_input)):\n",
    "    print(holdout_feature_input[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import keras.backend as K\n",
    "def customLoss(true,pred):\n",
    "    diff = pred - true\n",
    "\n",
    "    greater = K.greater(diff,0)\n",
    "    greater = K.cast(greater, K.floatx()) #0 for lower, 1 for greater\n",
    "    greater = greater + 1                 #1 for lower, 2 for greater\n",
    "\n",
    "    #use some kind of loss here, such as mse or mae, or pick one from keras\n",
    "    #using mse:\n",
    "    return K.mean(greater*K.square(diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_feature_recognizer(name,shape,dropout,recurrent_dropout,lr):\n",
    "    sequence_input = Input(shape=(shape[1],shape[2],), name=name)\n",
    "    \n",
    "    sequence_out = (LSTM(int(shape[2]), input_shape=(shape[1],shape[2]),dropout=dropout,recurrent_dropout=recurrent_dropout,kernel_regularizer=regularizers.l2(1e-6),return_sequences=True))(sequence_input)\n",
    "    sequence_out = (LSTM(int(shape[2]), input_shape=(shape[1],shape[2]-1),dropout=dropout,recurrent_dropout=recurrent_dropout,kernel_regularizer=regularizers.l2(1e-6),return_sequences=True))(sequence_input)\n",
    "    sequence_out = (LSTM(int(3), dropout=dropout,recurrent_dropout=recurrent_dropout,kernel_regularizer=regularizers.l2(1e-6)))(sequence_out)\n",
    "    preds = Dense(int(3)+int(shape[2]/2),activation=\"tanh\")(sequence_out)\n",
    "    preds = Dense(1,activation=\"tanh\")(sequence_out)\n",
    "    \n",
    "    model = Model(inputs=sequence_input,outputs=preds)\n",
    "    optimizer = Adam(lr)\n",
    "    model.compile(loss=customLoss,optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_feature_recognizer(name,shape,dropout,recurrent_dropout,lr):\n",
    "    \n",
    "    sequence_input = Input(shape=(shape[1],shape[2],), name=name)\n",
    "    sequence_out = (layers.Conv1D(64, int(shape[2]/2) + 1, activation='relu', input_shape= (shape[1],shape[2])))(sequence_input)\n",
    "    \n",
    "    \n",
    "\n",
    "    sequence_out = layers.Flatten()(sequence_out)\n",
    "    preds = Dense(140,activation=\"relu\")(sequence_out)\n",
    "    preds = Dense(40,activation=\"relu\")(preds)\n",
    "    preds = Dense(5,activation=\"relu\")(preds)\n",
    "    \n",
    "    model = Model(inputs=sequence_input,outputs=preds)\n",
    "    optimizer = Adam(lr)\n",
    "    model.compile(loss=customLoss,optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backbone_network(models,shapes,persistant_shape,dropout,recurrent_dropout,lr):\n",
    "    shapes = [i.shape for i in shapes]\n",
    "    features_input_1 = Input(shape=(shapes[0][1],shapes[0][2],), name=\"features_input1\")\n",
    "    features_input_2 = Input(shape=(shapes[1][1],shapes[1][2],), name=\"features_input2\")\n",
    "    features_input_3 = Input(shape=(shapes[2][1],shapes[2][2],), name=\"features_input3\")\n",
    "    features_input_4 = Input(shape=(shapes[3][1],shapes[3][2],), name=\"features_input4\")\n",
    "    features_input_5 = Input(shape=(shapes[4][1],shapes[4][2],), name=\"features_input5\")\n",
    "    features_inputs = [features_input_1,features_input_2,features_input_3,features_input_4,features_input_5]\n",
    "    #features_inputs = [features_input_1,features_input_2,features_input_3,features_input_4,features_input_5]\n",
    "    persistant_input = Input(shape=(persistant_shape,),name=\"persistant_input\")\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(models)):\n",
    "        result.append(models[i](features_inputs[i]))\n",
    "    x1 = tf.concat(result,axis=1)\n",
    "    x1 = Dense(20,activation=\"tanh\")(x1)\n",
    "    preds = Dense(1,activation=\"tanh\")(x1)\n",
    "    preds = Dropout(dropout)(preds)\n",
    "    preds = Concatenate()([persistant_input,preds])\n",
    "    preds = Dense(1,activation=\"tanh\")(x1)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[features_input_1,features_input_2,features_input_3,features_input_4,features_input_5,persistant_input],outputs=preds)\n",
    "    optimizer = Adam(lr)\n",
    "    model.compile(loss=customLoss,optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_dropout = 0.1\n",
    "dropout = 0.1\n",
    "recurrent_dropout = 0.1\n",
    "learning_rate = 3e-6\n",
    "\n",
    "#create our first model\n",
    "model_list = []\n",
    "for i in range(0,len(train_feature_input)):\n",
    "    model_list.append(LSTM_feature_recognizer(\"input\",train_feature_input[i].shape,dropout, recurrent_dropout, learning_rate))\n",
    "    #model_list.append(CNN_feature_recognizer(\"input\",train_feature_input[i].shape,dropout, recurrent_dropout, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.training.Model at 0x2c6b541cc18>,\n",
       " <tensorflow.python.keras.engine.training.Model at 0x2c6b6292e80>,\n",
       " <tensorflow.python.keras.engine.training.Model at 0x2c6b70d8978>,\n",
       " <tensorflow.python.keras.engine.training.Model at 0x2c6b7f4bbe0>,\n",
       " <tensorflow.python.keras.engine.training.Model at 0x2c6b8d91e80>]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_2 = 4e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = backbone_network(model_list,train_feature_input,train_persistance_norm.shape[1],dropout,recurrent_dropout,learning_rate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_108\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "features_input1 (InputLayer)    [(None, 5, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_input2 (InputLayer)    [(None, 3, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_input3 (InputLayer)    [(None, 3, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_input4 (InputLayer)    [(None, 9, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_input5 (InputLayer)    [(None, 39, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_102 (Model)               (None, 1)            76          features_input1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "model_103 (Model)               (None, 1)            76          features_input2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "model_104 (Model)               (None, 1)            76          features_input3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "model_105 (Model)               (None, 1)            76          features_input4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "model_106 (Model)               (None, 1)            76          features_input5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_15 (TensorFl [(None, 5)]          0           model_102[2][0]                  \n",
      "                                                                 model_103[2][0]                  \n",
      "                                                                 model_104[2][0]                  \n",
      "                                                                 model_105[2][0]                  \n",
      "                                                                 model_106[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_266 (Dense)               (None, 20)           120         tf_op_layer_concat_15[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "persistant_input (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_268 (Dense)               (None, 1)            21          dense_266[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 521\n",
      "Trainable params: 521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102862"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = \"D:\\AI4ImpactProject2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8758 samples, validate on 8759 samples\n",
      "Epoch 1/10\n",
      "8700/8758 [============================>.] - ETA: 0s - loss: 0.0465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0721 04:10:03.435312 16584 network.py:1327] This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002C9355D9710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8758/8758 [==============================] - 55s 6ms/sample - loss: 0.0464 - val_loss: 0.0568\n",
      "Epoch 2/10\n",
      "8700/8758 [============================>.] - ETA: 0s - loss: 0.0316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0721 04:10:27.475705 16584 network.py:1327] This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002C9355D9710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8758/8758 [==============================] - 26s 3ms/sample - loss: 0.0316 - val_loss: 0.0376\n",
      "Epoch 3/10\n",
      "8700/8758 [============================>.] - ETA: 0s - loss: 0.0272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0721 04:10:52.318884 16584 network.py:1327] This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002C9355D9710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8758/8758 [==============================] - 27s 3ms/sample - loss: 0.0272 - val_loss: 0.0330\n",
      "Epoch 4/10\n",
      "8758/8758 [==============================] - 21s 2ms/sample - loss: 0.0250 - val_loss: 0.0330\n",
      "Epoch 5/10\n",
      "8700/8758 [============================>.] - ETA: 0s - loss: 0.0240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0721 04:11:39.957179 16584 network.py:1327] This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002C9355D9710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8758/8758 [==============================] - 24s 3ms/sample - loss: 0.0239 - val_loss: 0.0312\n",
      "Epoch 6/10\n",
      "8700/8758 [============================>.] - ETA: 0s - loss: 0.0235"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback_no_diff = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "history1 = model.fit([*train_feature_input,train_persistance_norm], train_y_norm,validation_data=([*test_feature_input,test_persistance_norm],test_y_norm),epochs = 10, batch_size = 100, verbose = 1 ,callbacks=[model_checkpoint_callback_no_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_hat = model.predict([*test_feature_input,test_persistance_norm])\n",
    "test_y_hat_inversed = y_scaler_sc.inverse_transform(test_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test diff Deep learning\")\n",
    "print(np.sqrt(mean_squared_error(test_y_hat_inversed,test_y)))\n",
    "print(mean_absolute_error(test_y_hat_inversed,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_lag(wind_sum_T_plus_18,1,18)[2:-lost]\n",
    "p_train = p[:train_index]\n",
    "p_test = p[train_index:test_index]\n",
    "p_holdout = p[test_index:holdout_index]\n",
    "print(\"test persistance\")\n",
    "print(np.sqrt(mean_squared_error(p_test,test_y)))\n",
    "print(mean_absolute_error(p_test,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_y_hat = model.predict([*holdout_feature_input,holdout_persistance_norm])\n",
    "holdout_y_hat_inversed = y_scaler_sc.inverse_transform(holdout_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"holdout diff Deep learning\")\n",
    "print(np.sqrt(mean_squared_error(holdout_y_hat_inversed,holdout_y)))\n",
    "print(mean_absolute_error(holdout_y_hat_inversed,holdout_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"holdout persistant\")\n",
    "print(np.sqrt(mean_squared_error(p_holdout,holdout_y)))\n",
    "print(mean_absolute_error(p_holdout,holdout_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading(forecast,actual):\n",
    "#execute the trading from the result of forecast and actual energy production\n",
    "#forecast: an 1D array of forecast values (Unit:kWh)\n",
    "#actual: an 1D array of actual values (Unit:kWh)\n",
    "  \n",
    "    #initial budget\n",
    "    budget=1e9\n",
    "    #counters initialize: short falling and panalty counter\n",
    "    SFcount=0;\n",
    "    Pcount=0;\n",
    "    cashFlow=[1e9]\n",
    "    \n",
    "    for f,a in zip(forecast,actual):\n",
    "        \n",
    "        if f <= a:\n",
    "            budget += f*10\n",
    "        elif f > a:#short falling\n",
    "            #calculate cost of spot price energy\n",
    "            budget += a*10\n",
    "            spotP = 20*(f-a)\n",
    "            SFcount+= 1\n",
    "            if budget >= spotP:\n",
    "                budget -= 20*(f-a)\n",
    "            else:\n",
    "                #receive penalty from the government\n",
    "                if budget>0:\n",
    "                    #buy from grid if budget not equal to 0\n",
    "                    spotP-=budget\n",
    "                    budget=0\n",
    "                #fine =5* spotP\n",
    "                budget -= 5*spotP\n",
    "                Pcount+=1\n",
    "        cashFlow.append(budget)\n",
    "       \n",
    "    timeStep= list(range(0, len(cashFlow)))\n",
    "    #Reporting\n",
    "    plt.plot(timeStep,cashFlow)\n",
    "    plt.show()\n",
    "    print (\"resultant budget: \",budget)\n",
    "    print (\"net profit: \",budget-1e9)\n",
    "    print (\"number of short falling: \",SFcount )\n",
    "    print (\"number of panalty: \",Pcount )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_holdout.head() #persistant lead_time - 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_y.head()#persistant lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading(np.array(holdout_y),np.array(p_holdout)) #persistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_holdout = np.array([i if i>0 else 0  for i in holdout_y_hat_inversed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_holdout-holdout_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trading(np.array(holdout_y),holdout_y_hat_inversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
